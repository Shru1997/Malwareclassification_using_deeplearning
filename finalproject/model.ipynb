{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import keras\n",
    "import os,shutil\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Activation\n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data_dir = './malimg_dataset/malimg_paper_dataset_imgs'\n",
    "base_dir = './malimg_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(base_dir,'train')\n",
    "validation_dir = os.path.join(base_dir,'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Adialer.C', 'Agent.FYI', 'Allaple.A', 'Allaple.L', 'Alueron.gen!J', 'Autorun.K', 'C2LOP.P', 'C2LOP.gen!g', 'Dialplatform.B', 'Dontovo.A', 'Fakerean', 'Instantaccess', 'Lolyda.AA1', 'Lolyda.AA2', 'Lolyda.AA3', 'Lolyda.AT', 'Malex.gen!J', 'Obfuscator.AD', 'Rbot!gen', 'Skintrim.N', 'Swizzor.gen!E', 'Swizzor.gen!I', 'VB.AT', 'Wintrim.BX', 'Yuner.A', 'malimg_dataset_readme.txt']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(list(os.listdir(original_data_dir))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adialer.C\n"
     ]
    },
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: './malimg_dataset\\\\train\\\\Adialer.C'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7e3b4614b1b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclass_dir_list\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: './malimg_dataset\\\\train\\\\Adialer.C'"
     ]
    }
   ],
   "source": [
    "class_dir_list = sorted(list(os.listdir(original_data_dir)))\n",
    "\n",
    "if os.path.isdir(base_dir) == False:\n",
    "    os.mkdir(base_dir)\n",
    "if os.path.isdir(train_dir) == False:\n",
    "    os.mkdir(train_dir)\n",
    "    os.mkdir(validation_dir)\n",
    "  \n",
    "  \n",
    "for cl in class_dir_list :\n",
    "    print(cl)\n",
    "    os.mkdir(os.path.join(train_dir,cl))\n",
    "    os.mkdir(os.path.join(validation_dir,cl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(directory):\n",
    "    return (f for f in os.listdir(directory))\n",
    "\n",
    "def copy_classes(class_objs, cl, dest_dir ) :\n",
    "    src_dir = os.path.join(original_data_dir,cl)\n",
    "    for obj in class_objs:\n",
    "        src_file = os.path.join(src_dir, obj)\n",
    "        dst_dir = os.path.join(dest_dir, obj)\n",
    "        shutil.copyfile(src_file, dst_dir)\n",
    "    \n",
    "for cl in class_dir_list :\n",
    "    if cl != 'malimg_dataset_readme.txt' : \n",
    "        class_data_list = list(list_files(os.path.join(original_data_dir,cl)))\n",
    "        portion = int(np.floor((len(class_data_list)*8/10)))\n",
    "        copy_classes(class_data_list[:portion],cl,os.path.join(train_dir, cl))\n",
    "        copy_classes(class_data_list[portion:],cl,os.path.join(validation_dir, cl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(shape = 150, samePadding = False):\n",
    "    _padding = 'same' if samePadding else 'valid'\n",
    "    _model = models.Sequential()\n",
    "    _model.add(layers.Conv2D(10, (3, 3), activation='relu', input_shape = (shape, shape, 3), padding= _padding))\n",
    "    _model.add(layers.MaxPooling2D(2, 2))\n",
    "    _model.add(layers.Conv2D(64, (3, 3), activation='relu', padding=_padding))\n",
    "    _model.add(layers.MaxPooling2D(2, 2))\n",
    "    _model.add(layers.Conv2D(64, (3, 3), activation='relu', padding=_padding))\n",
    "    _model.add(layers.MaxPooling2D(2, 2))\n",
    "    _model.add(layers.Conv2D(128, (3, 3), activation='relu', padding=_padding))\n",
    "    _model.add(layers.MaxPooling2D(2, 2))\n",
    "    _model.add(layers.Flatten())\n",
    "    _model.add(layers.Dense(512, activation='relu'))\n",
    "    _model.add(layers.Dense(25, activation='softmax'))\n",
    "  \n",
    "  #alware_Model = models.Sequential()\n",
    "  #alware_Model.add(layers.Conv2D(32, kernel_size=(3,3),input_shape=(shape,shape,3),))\n",
    "  #alware_Model.add(layers.LeakyReLU(.1))\n",
    "  #alware_Model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "  #alware_Model.add(layers.Conv2D(64, kernel_size=(3,3),))\n",
    "  #alware_Model.add(layers.LeakyReLU(.1))\n",
    "  #alware_Model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "  #alware_Model.add(layers.Conv2D(64, (3, 3)))\n",
    "  #alware_Model.add(layers.LeakyReLU(.1))\n",
    "  #alware_Model.add(layers.Dense(128 ))\n",
    "  #alware_Model.add(layers.LeakyReLU(.1))\n",
    "  #alware_Model.add(layers.Dropout(0.4))\n",
    "  #alware_Model.add(layers.Flatten())\n",
    "  #alware_Model.add(layers.Dense(25 ))\n",
    "\n",
    "    opt = keras.optimizers.rmsprop(lr=1e-3)\n",
    "    _model.compile(loss='categorical_crossentropy',\n",
    "               optimizer= opt,\n",
    "               metrics = ['accuracy'])\n",
    "    return _model\n",
    "\n",
    "#################################################\n",
    "def fit_model_gen(_model,\n",
    "                  _train_datagen = ImageDataGenerator(rescale=1./255),\n",
    "                  _train_batch_size=20,\n",
    "                  _epochs = 30,\n",
    "                  _shuffle = False,\n",
    "                  _modelName = 'malimg_model.h5',\n",
    "                  _shape=150):\n",
    "                 \n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = _train_datagen.flow_from_directory(\n",
    "      train_dir,\n",
    "      target_size=(_shape,_shape),\n",
    "      batch_size=20,\n",
    "      class_mode = 'categorical')\n",
    "\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "      validation_dir,\n",
    "      target_size=(_shape,_shape),\n",
    "      batch_size=_train_batch_size,\n",
    "      class_mode = 'categorical')\n",
    "\n",
    "\n",
    "    _history = _model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch = 100,\n",
    "      epochs = _epochs,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,\n",
    "      shuffle=_shuffle,\n",
    "      workers=0)\n",
    "  \n",
    "    model.save(_modelName)\n",
    "    model.save('/content/drive/My Drive/malimg_dataset/' + _modelName)\n",
    "    return _history\n",
    "\n",
    "#################################################\n",
    "def train_val_by_metric(history,metric):\n",
    "    history_dict = history.history\n",
    "  #history_dict.keys()\n",
    "    values = history_dict[metric]\n",
    "    val_values = history_dict['val_'+metric]\n",
    "\n",
    "    epochs = range(1, len(values) + 1)\n",
    "  \n",
    "    plt.plot(epochs, values, 'bo', label= 'Training '+metric)\n",
    "    plt.plot(epochs, val_values, 'b', label= 'Validation '+metric)\n",
    "    metricTitle = 'Loss' if metric == 'loss' else 'Accuracy'\n",
    "    plt.title('Training and validation '+metricTitle)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(metricTitle)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "###################################################\n",
    "def train_val_res(history):\n",
    "    train_val_by_metric(history,'loss')\n",
    "    train_val_by_metric(history,'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_shape = 150\n",
    "model = create_model(shape = _shape , samePadding = True)\n",
    "model.summary()\n",
    "history = fit_model_gen(model,_shape = _shape,_train_batch_size=64,_epochs = 20,_shuffle = True)\n",
    "train_val_res(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model1=load_model('./malimg_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,acc=model1.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy is {}'.format(str(100*acc)+'%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model1.predict(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "pred= model1.predict_generator(validation_generator)\n",
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "labels = (validation_generator.class_indices)\n",
    "print(labels)\n",
    "labels2 = dict((v,k) for k,v in labels.items())\n",
    "predictions=[]\n",
    "# predictions = [labels[k] for k in predicted_class_indices]\n",
    "for k in predicted_class_indices:\n",
    "  predictions.append(labels2[k])\n",
    "predicted_class_indices.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,recall_score,classification_report,precision_score,f1_score\n",
    "y_true=validation_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(predicted_class_indices,y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recall_score(predicted_class_indices,y_true,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(precision_score(predicted_class_indices,y_true,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(predicted_class_indices,y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_score(predicted_class_indices,y_true,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
