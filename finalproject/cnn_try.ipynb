{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import keras\n",
    "import os,shutil\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Activation\n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data_dir = './malimg_dataset/malimg_paper_dataset_imgs'\n",
    "base_dir = './malimg_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(base_dir,'train')\n",
    "validation_dir = os.path.join(base_dir,'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Adialer.C', 'Agent.FYI', 'Allaple.A', 'Allaple.L', 'Alueron.gen!J', 'Autorun.K', 'C2LOP.P', 'C2LOP.gen!g', 'Dialplatform.B', 'Dontovo.A', 'Fakerean', 'Instantaccess', 'Lolyda.AA1', 'Lolyda.AA2', 'Lolyda.AA3', 'Lolyda.AT', 'Malex.gen!J', 'Obfuscator.AD', 'Rbot!gen', 'Skintrim.N', 'Swizzor.gen!E', 'Swizzor.gen!I', 'VB.AT', 'Wintrim.BX', 'Yuner.A', 'malimg_dataset_readme.txt']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(list(os.listdir(original_data_dir))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_dir_list = sorted(list(os.listdir(original_data_dir)))\n",
    "\n",
    "if os.path.isdir(base_dir) == False:\n",
    "    os.mkdir(base_dir)\n",
    "if os.path.isdir(train_dir) == False:\n",
    "    os.mkdir(train_dir)\n",
    "    os.mkdir(validation_dir)\n",
    "  \n",
    "  \n",
    "for cl in class_dir_list :\n",
    "    if os.path.isdir(os.path.join(train_dir,cl))==False:\n",
    "        os.mkdir(os.path.join(train_dir,cl))\n",
    "        os.mkdir(os.path.join(validation_dir,cl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(directory):\n",
    "    return (f for f in os.listdir(directory))\n",
    "\n",
    "def copy_classes(class_objs, cl, dest_dir ) :\n",
    "    src_dir = os.path.join(original_data_dir,cl)\n",
    "    for obj in class_objs:\n",
    "        src_file = os.path.join(src_dir, obj)\n",
    "        dst_dir = os.path.join(dest_dir, obj)\n",
    "        shutil.copyfile(src_file, dst_dir)\n",
    "    \n",
    "for cl in class_dir_list :\n",
    "    if cl != 'malimg_dataset_readme.txt' : \n",
    "        class_data_list = list(list_files(os.path.join(original_data_dir,cl)))\n",
    "        portion = int(np.floor((len(class_data_list)*8/10)))\n",
    "        copy_classes(class_data_list[:portion],cl,os.path.join(train_dir, cl))\n",
    "        copy_classes(class_data_list[portion:],cl,os.path.join(validation_dir, cl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(shape = 150, samePadding = False):\n",
    "    _padding = 'same' if samePadding else 'valid'\n",
    "    _model = models.Sequential()\n",
    "    _model.add(layers.Conv2D(10, (3, 3), activation='relu', input_shape = (shape, shape, 3), padding= _padding))\n",
    "    _model.add(layers.MaxPooling2D(2, 2))\n",
    "    _model.add(layers.Conv2D(64, (3, 3), activation='relu', padding=_padding))\n",
    "    _model.add(layers.MaxPooling2D(2, 2))\n",
    "    _model.add(layers.Conv2D(64, (3, 3), activation='relu', padding=_padding))\n",
    "    _model.add(layers.MaxPooling2D(2, 2))\n",
    "    _model.add(layers.Conv2D(128, (3, 3), activation='relu', padding=_padding))\n",
    "    _model.add(layers.MaxPooling2D(2, 2))\n",
    "    _model.add(layers.Flatten())\n",
    "    _model.add(layers.Dense(512, activation='relu'))\n",
    "    _model.add(layers.Dense(25, activation='softmax'))\n",
    "  \n",
    "  #alware_Model = models.Sequential()\n",
    "  #alware_Model.add(layers.Conv2D(32, kernel_size=(3,3),input_shape=(shape,shape,3),))\n",
    "  #alware_Model.add(layers.LeakyReLU(.1))\n",
    "  #alware_Model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "  #alware_Model.add(layers.Conv2D(64, kernel_size=(3,3),))\n",
    "  #alware_Model.add(layers.LeakyReLU(.1))\n",
    "  #alware_Model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "  #alware_Model.add(layers.Conv2D(64, (3, 3)))\n",
    "  #alware_Model.add(layers.LeakyReLU(.1))\n",
    "  #alware_Model.add(layers.Dense(128 ))\n",
    "  #alware_Model.add(layers.LeakyReLU(.1))\n",
    "  #alware_Model.add(layers.Dropout(0.4))\n",
    "  #alware_Model.add(layers.Flatten())\n",
    "  #alware_Model.add(layers.Dense(25 ))\n",
    "\n",
    "    opt = keras.optimizers.rmsprop(lr=1e-3)\n",
    "    _model.compile(loss='categorical_crossentropy',\n",
    "               optimizer= opt,\n",
    "               metrics = ['accuracy'])\n",
    "    return _model\n",
    "\n",
    "#################################################\n",
    "def fit_model_gen(_model,\n",
    "                  _train_datagen = ImageDataGenerator(rescale=1./255),\n",
    "                  _train_batch_size=20,\n",
    "                  _epochs = 30,\n",
    "                  _shuffle = False,\n",
    "                  _modelName = 'malimg_model_try.h5',\n",
    "                  _shape=150):\n",
    "                 \n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = _train_datagen.flow_from_directory(\n",
    "      train_dir,\n",
    "      target_size=(_shape,_shape),\n",
    "      batch_size=20,\n",
    "      class_mode = 'categorical')\n",
    "\n",
    "    global validation_generator\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "      validation_dir,\n",
    "      target_size=(_shape,_shape),\n",
    "      batch_size=_train_batch_size,\n",
    "      class_mode = 'categorical')\n",
    "    print(validation_generator)\n",
    "\n",
    "\n",
    "    # _history = _model.fit_generator(\n",
    "    #   train_generator,\n",
    "    #   steps_per_epoch = 100,\n",
    "    #   epochs = _epochs,\n",
    "    #   validation_data=validation_generator,\n",
    "    #   validation_steps=50,\n",
    "    #   shuffle=_shuffle)\n",
    "  \n",
    "    model.save(_modelName)\n",
    "    # return _history\n",
    "\n",
    "#################################################\n",
    "def train_val_by_metric(history,metric):\n",
    "    history_dict = history.history\n",
    "  #history_dict.keys()\n",
    "    values = history_dict[metric]\n",
    "    val_values = history_dict['val_'+metric]\n",
    "\n",
    "    epochs = range(1, len(values) + 1)\n",
    "  \n",
    "    plt.plot(epochs, values, 'bo', label= 'Training '+metric)\n",
    "    plt.plot(epochs, val_values, 'b', label= 'Validation '+metric)\n",
    "    metricTitle = 'Loss' if metric == 'loss' else 'Accuracy'\n",
    "    plt.title('Training and validation '+metricTitle)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(metricTitle)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "###################################################\n",
    "def train_val_res(history):\n",
    "    train_val_by_metric(history,'loss')\n",
    "    train_val_by_metric(history,'acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 150, 150, 10)      280       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 75, 75, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 75, 75, 64)        5824      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 37, 37, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 18, 18, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 10368)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               5308928   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                12825     \n",
      "=================================================================\n",
      "Total params: 5,438,641\n",
      "Trainable params: 5,438,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Found 7459 images belonging to 26 classes.\n",
      "Found 1880 images belonging to 26 classes.\n",
      "<keras.preprocessing.image.DirectoryIterator object at 0x0000026D1EBFDD88>\n"
     ]
    }
   ],
   "source": [
    "_shape = 150\n",
    "model = create_model(shape = _shape , samePadding = True)\n",
    "model.summary()\n",
    "# history = fit_model_gen(model,_shape = _shape,_train_batch_size=64,_epochs = 20,_shuffle = True)\n",
    "fit_model_gen(model,_shape = _shape,_train_batch_size=64,_epochs = 20,_shuffle = True)\n",
    "# train_val_res(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model1=load_model('./malimg_model_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_2 to have shape (25,) but got array with shape (26,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-64a8a9c273c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda1\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1336\u001b[0m                 \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m                 \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1338\u001b[1;33m                 use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m   1339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1340\u001b[0m         \u001b[1;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda1\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda1\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[1;34m(self, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m   1789\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1790\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1791\u001b[1;33m             verbose=verbose)\n\u001b[0m\u001b[0;32m   1792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1793\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda1\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[1;34m(model, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m    399\u001b[0m             outs = model.test_on_batch(x, y,\n\u001b[0;32m    400\u001b[0m                                        \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 401\u001b[1;33m                                        reset_metrics=False)\n\u001b[0m\u001b[0;32m    402\u001b[0m             \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m             \u001b[0mouts_per_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda1\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtest_on_batch\u001b[1;34m(self, x, y, sample_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1551\u001b[0m         x, y, sample_weights = self._standardize_user_data(\n\u001b[0;32m   1552\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1553\u001b[1;33m             sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m   1554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1555\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda1\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda1\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    143\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    146\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_2 to have shape (25,) but got array with shape (26,)"
     ]
    }
   ],
   "source": [
    "_,acc=model1.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
